\section{Workflow}

\begin{figure*}[t]
 \centering
 \subfloat[]{\label{fig:his0}\includegraphics[width=0.166\linewidth]{figures/hi0.eps}}
 \subfloat[]{\label{fig:his1}\includegraphics[width=0.166\linewidth]{figures/hi1.eps}}
 \subfloat[]{\label{fig:his2}\includegraphics[width=0.166\linewidth]{figures/hi2.eps}}
 \subfloat[]{\label{fig:his3}\includegraphics[width=0.166\linewidth]{figures/hi3.eps}}
 \subfloat[]{\label{fig:his4}\includegraphics[width=0.166\linewidth]{figures/hi4.eps}}
 \subfloat[]{\label{fig:his5}\includegraphics[width=0.166\linewidth]{figures/hi5.eps}}
 \caption{\label{fig:his}Visibility Equalizers.}
\end{figure*}

Cull objects are defined...

\section{Property-Based Clipping}

%Additionally to defining where instances will be clipped, our system offer the mean to selectively chose the concentration of displayed elements for each protein types.
%These values are controlled by the user via the user interface. 

Our data comprise of a dense set of macromolecules, encapsulated in compartments with several degrees of nesting. 

Molecules are grouped by type and compartment, this information is contained in the scene file generated by cellPACK.

Basic filtering parameters allows to manipulate the visibility of entire set of instances based on their type, independently or not from a geometrical cull object.

Each cull object has its own parameters which are defined for all the ingredients type as shown in the overview figure XX.

When a geometrical shape is associated to the cull object, the filtered visibility will only be applied to the region defined by the geometry, e.g, plane, sphere, cone...

User can modify these filtering parameters via the user interface.

There are two parameters that are not directly related to object-space or view-space cull geometries.

First is the percentage of visible elements of a given type. 
We refer to this value as ingredient clip probability.

Second are the biochemical properties such as mass or quantities.

Additionally, there are more parameters which can influence when an instance is culled and which are depending on an actual geometry cull object, those are defined in section XX.


\subsection{Histograms}

To provide a clear overview of the scene properties, we display histograms for each ingredient type that indicate information about their visibility.

By default we chose to show three ranges in each histogram. The section of the histogram (dark green region) shows the percentage of instances that are currently visible on the screen. 
The entire green section (dark \& light green) represents the percentage of instances that are actually rendered.

In order to fill histograms with the correct value, we perform book-keeping of both clipped and visible instances, which we recompute after each changes in cut objects or camera.

Histograms are sorted per compartment in a tree layout, additional histograms are also displayed for the compartments, averaging all the values of the ingredients contained inside.

Histograms are also interactive.

Upon manipulation of the right end of the second range of the histogram (light green) the system will increase or decrease the clip probability internally, resulting in changes in displayed quantities.

%The dragging of the range is directly influencing the internal value "value1". 
The culled states of the instances will get subsequently updated and counted in order to update the histogram value.

Because of the degree of indirection between the user action and the view, we are also able change the way we display information in the histograms, without affecting the way of interacting with them.

For instance, quantities are relative by default, i.e, they represent a percentage, but they can also be displayed as absolute.

For displaying absolute quantities we support logarithmic scaling to ensure low quantities to be visible in the histograms.

An logarithmic ruler is also provided to help the user understanding the displayed values


\subsection{Instance Discarding}

Prior to the rendering each single instance is evaluated to determine if it shall be rendered.

The cut objects how instances shall be discarded and they are applied sequentially.

Internally the filtering is applied just after the object-space culling as shown in figure XX.

First is applied the filtering based the clip probability.

For each instance, we compare a uniformly distributed random number with the clip probability.

If the random number is higher than the probability, the instance is marked as culled, and will not be rendered. 

The random number is initially set for each individual instance and remain the same, in order to guaranty reproducibility of the scene.

Secondly, instances are filtered according to their biochemical properties, for each cut object and each protein types the user defines ranges values for the both quantities and molecular weight.

Instances whose properties lie outside on these ranges are marked as culled and discarded.

For the book-keeping is the clipped ingredient we count for each ingredient type how many instances where discarded in total, for all active cut object.



\section{Shape-Based Clipping}

\subsection{Object-Space}

The basic parameters of the cull objects define the global number of clipped instances for each ingredient type.

Additionally, they can be associated with geometrical shapes to determine where the clipping should take place.


\subsubsection{Analytical Distance Evaluation}

At the very beginning of the process, for each instance, prior to the filtering, we determine if the instance if located in the region defined by the geometry.

Our system currently supports the following set of primitive shapes (plane, cube, sphere, cylinder and cone)

Although simple, it may still be computationally expensive to evaluate the signed distance of those shapes with a large number of points in space, using a mesh-based representation.

To accelerate the computation we solve the problem analytically using a signed distance field (SDF).

Using such analytical representation reduces the problem of evaluating the distance to solving trivial 3D shapes equations.

It is also possible to apply traditional transform operations to the distance field, such as translation, rotation and scaling.

The effect of the shape-based clipping can also be inverted by inverting the result of the signed distance function, offering more usage flexibility.

Using, for instance, a spherical shape, the clip region would normally be set to the inside of the sphere, while in inverted mode it would correspond to the inside of the sphere. 

\subsubsection{Gradient Clipping}

We provide additional options to gradually remove instances given a geometrical shape.

The purpose is to facilitate the removal of instances, primarily for illustration purposes.

\textbf{TODO PMINDEK:} Talk about gradient clipping here


\subsection{View-Space}

While object-space culling using primitive shapes allows for a great degree of flexibility, it requires cumbersome manual operations for complex set-ups, and is also limited in terms of shapes diversities.

We additionally provide a method to specify a set of ingredient types as focus, and to selectively remove occluding instances.

\subsubsection{Mask-Based Approach}

Due to the potentially large number of instances in our scenes, we use accelerate the computation of occluding instances using an image-based approach on the GPU.

To determine what instances are in front of the focus, we first separately render a mask containing all the focus elements.

Focus ingredients are priorly selected from the histogram view via a dedicated toggle.

There can be only one mask created per cut object.

The mask is rendered using bounding sphere in order to lower to cost of the additional render pass.

The render pass sets the depth buffer in order to let subsequent draw calls to pass only if they are overlapping the focus region.

Subsequently, we draw the bounding sphere of the remaining instances over the mask, fragments that will pass the depth test are therefore guaranteed to belong to an object occluding the focus, with at least one pixel.

From the fragment program we then mark the occluding instance as culled, in a similar way as we would normally cull an instance. 





\subsubsection{Aperture Effect}

Image-based mask culling using depth and stencil test

\section{Depth cues and Enhancements}

\section{Results and Discussion}


\section{Evaluation}

\begin{figure}[t]
 \centering
 \includegraphics[width=\linewidth]{figures/results01.eps}
 \caption{\label{fig:results01}An illustration of the HIV virus in the blood serum utilizing cutaways created with our approach.}
\end{figure}

\section{Conclusions}