\section{Workflow}

\begin{figure*}[t]
 \centering
 \subfloat[]{\label{fig:his0}\includegraphics[width=0.166\linewidth]{figures/hi0.eps}}
 \subfloat[]{\label{fig:his1}\includegraphics[width=0.166\linewidth]{figures/hi1.eps}}
 \subfloat[]{\label{fig:his2}\includegraphics[width=0.166\linewidth]{figures/hi2.eps}}
 \subfloat[]{\label{fig:his3}\includegraphics[width=0.166\linewidth]{figures/hi3.eps}}
 \subfloat[]{\label{fig:his4}\includegraphics[width=0.166\linewidth]{figures/hi4.eps}}
 \subfloat[]{\label{fig:his5}\includegraphics[width=0.166\linewidth]{figures/hi5.eps}}
 \caption{\label{fig:his}Visibility Equalizers.}
\end{figure*}


%SENTENCES DUMP

%Our data comprise of a dense set of macromolecules, encapsulated in compartments with several degrees of nesting. 

%Molecules are grouped by type and compartment, this information is contained in the scene file generated by cellPACK.

%Basic filtering parameters allows to manipulate the visibility of entire set of instances based on their type, independently or not from a geometrical cull object.

%Each cull object has its own parameters which are defined for all the ingredients type as shown in the overview figure XX.

%When associated with geometrical shape, the cull object will only be influence to the region defined by the geometry, e.g, plane, sphere, cone...

%The cut objects how instances shall be discarded and they are applied sequentially.

%Internally the filtering is applied just after the object-space culling as shown in figure XX.

%User can modify these filtering parameters via the user interface.

%Additionally, there are more parameters which can influence when an instance is culled and which are related to a geometrical shape, those are defined in section XX.

%Additionally to defining where instances will be clipped, our system offer the mean to selectively chose the concentration of displayed elements for each protein types.
%These values are controlled by the user via the user interface. 





\section{Object-Space Clipping}

Cull object define how instances of a given ingredient type shall be clipped.

Each cull object stores clip parameters for each ingredient types.

Additionally cut parameters can be associated with a geometrical shape that localize the clipping in the domain.

Cull objects are applied in serial as shown in figure XX.

Internally, for each cull object and for each single instance, we first determine the region of the clipping and then we determine if the instance shall be clipped according the cull object parameters. 

Moreover, additional gradient parameters allows for advanced customization of the clipping region.



\subsection{Clip Parameters}

For each cut object and for each ingredient type, there are two basic parameters that allow to control the visibility of entire sets of instances based on their type.

When associated with geometrical shape, the cull object will only influence thee sub-region of the domain, defined by the geometry, e.g, plane, sphere, cone...

It is worth mentioning that in case no shape is associated with the cull object, the clipping will be evaluated to the entire domain.

****

The first parameter is the percentage of visible elements of a given type. 

We refer to this value as object-space clip probability.

This value allows us to control the degree of fuzziness of the clipping.

The other filtering parameters are related to biochemical properties and allows us to control the clipping based on the mass and/or quantity of given ingredient types.

****

Prior to the rendering, after localizing the clip region, each single instance is evaluated in order to determine if it shall be clipped.

First is applied the filtering based on the clip probability on the ingredient type.

For each instance, we compare a uniformly distributed random number with the clip probability.

If the random number is higher than the probability, the instance is marked as culled, and will not be rendered. 

The random number is initially set for each individual instance and remain the same for each re-evaluation of the clipping, in order to guaranty reproducibility of the scene.

Secondly, instances are filtered according to their biochemical properties, for each cut object and each ingredient types the user defines range values for the both quantities and molecular weight.

Instances whose properties lie outside on these ranges are marked as culled and will not be rendered.


\subsection{Analytical Distance Evaluation}

At the very beginning of the process, for each instance, the first task of the clipping is to determine whether an instance is located in the sub-region defined by the geometry.

Our system currently supports the following set of primitive shapes (plane, cube, sphere, cylinder and cone)

To evaluate if an instance lies inside or outside the clip object region, we compute the signed distance between the instance bounding sphere and the closest point on the region surface. 

Although the supported shapes have a simple topology, it may still be computationally expensive, using a mesh-based representation, to evaluate the signed distance of a large number of instances.

Indeed, using a triangle-based discretization for the shape would imply evaluating the signed distance between the instances and every single triangle of the mesh.

To accelerate the computation we solve the problem analytically using a mathematical description of the 3D signed distance field (SDF).

Using such representation instead reduces the problem of evaluating the signed distance to solving trivial equations.

It is also possible to apply traditional transform operations to the distance field, such as translation, rotation and scaling.

The clipping region can also be reversed by inverting the result of the signed distance function, offering users flexibility.

Using, for instance, a spherical shape, the clip region would be set to the inside of the sphere by default, while in inverted mode it would correspond to the inside of the sphere. 

\subsection{Gradient}

We provide additional options to gradually remove instances given a geometrical shape.

The purpose is to facilitate the removal of instances, primarily for illustration purposes.

\textbf{TODO PMINDEK:} Talk about gradient clipping here




\section{Visibility Histograms}


To provide a clear overview of the scene properties, we display histograms for each ingredient type that indicate information about their visibility.

By default we chose to show three ranges in each histogram. The section of the histogram (dark green region) shows the percentage of instances that are currently visible on the screen. 
The entire green section (dark \& light green) represents the percentage of instances that are actually rendered.

In order to fill histograms with the correct value, we perform book-keeping of both clipped and visible instances, which we recompute after each changes in cut objects or camera.

Histograms are sorted per compartment in a tree layout, additional histograms are also displayed for the compartments, averaging all the values of the ingredients contained inside.

Histograms are also interactive.

Upon manipulation of the right end of the second range of the histogram (light green) the system will increase or decrease the clip probability internally, resulting in changes in displayed quantities.

%The dragging of the range is directly influencing the internal value "value1". 
The culled states of the instances will get subsequently updated and counted in order to update the histogram value.

Because of the degree of indirection between the user action and the view, we are also able change the way we display information in the histograms, without affecting the way of interacting with them.

For instance, quantities are relative by default, i.e, they represent a percentage, but they can also be displayed as absolute.

For displaying absolute quantities we support logarithmic scaling to ensure low quantities to be visible in the histograms.

An logarithmic ruler is also provided to help the user understanding the displayed values


\subsection{Instance Discarding}

Prior to the rendering each single instance is evaluated to determine if it shall be rendered.

The cut objects how instances shall be discarded and they are applied sequentially.

Internally the filtering is applied just after the object-space culling as shown in figure XX.

First is applied the filtering based the clip probability.

For each instance, we compare a uniformly distributed random number with the clip probability.

If the random number is higher than the probability, the instance is marked as culled, and will not be rendered. 

The random number is initially set for each individual instance and remain the same, in order to guaranty reproducibility of the scene.

Secondly, instances are filtered according to their biochemical properties, for each cut object and each protein types the user defines ranges values for the both quantities and molecular weight.

Instances whose properties lie outside on these ranges are marked as culled and discarded.

For the book-keeping is the clipped ingredient we count for each ingredient type how many instances where discarded in total, for all active cut object.






\section{View-Dependent Clipping}

While object-space culling using primitive shapes allows for a great degree of flexibility, it requires cumbersome manual operations for complex set-ups, and is also limited in terms of shapes diversities.

We additionally provide a method to specify a set of ingredient types as focus, and to selectively remove occluding instances.

\subsubsection{Mask-Based Approach}

Due to the potentially large number of instances in our scenes, we use accelerate the computation of occluding instances using an image-based approach on the GPU.

To determine what instances are in front of the focus, we first separately render a mask containing all the focus elements.

Focus ingredients are priorly selected from the histogram view via a dedicated toggle.

There can be only one mask created per cut object.

The mask is rendered using bounding sphere in order to lower to cost of the additional render pass.

The render pass sets the depth buffer in order to let subsequent draw calls to pass only if they are overlapping the focus region.

Subsequently, we draw the bounding sphere of the remaining instances over the mask, fragments that will pass the depth test are therefore guaranteed to belong to an object occluding the focus, with at least one pixel.

From the fragment program we then mark the occluding instance as culled, in a similar way as we would normally cull an instance. 


\subsection{Aperture Effect}

Image-based mask culling using depth and stencil test

\subsection{Island Effect}

Image-based mask culling using depth and stencil test


\section{Depth cues and Enhancements}

\section{Results and Discussion}

\section{Evaluation}

\begin{figure}[t]
 \centering
 \includegraphics[width=\linewidth]{figures/results01.eps}
 \caption{\label{fig:results01}An illustration of the HIV virus in the blood serum utilizing cutaways created with our approach.}
\end{figure}

\section{Conclusions}